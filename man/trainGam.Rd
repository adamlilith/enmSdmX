% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trainGam.r
\name{trainGam}
\alias{trainGam}
\title{Calibrate a generalized additive model (GAM)}
\usage{
trainGam(
  data,
  resp = names(data)[1],
  preds = names(data)[2:ncol(data)],
  family = "binomial",
  gamma = 1,
  construct = TRUE,
  select = TRUE,
  presPerTermInitial = 10,
  presPerTermFinal = 10,
  initialTerms = 8,
  interaction = "te",
  w = TRUE,
  out = "model",
  verbose = FALSE,
  ...
)
}
\arguments{
\item{data}{Data frame.  Must contain fields with same names as in \code{preds} object.}

\item{resp}{Character or integer. Name or column index of response variable. Default is to use the first column in \code{data}.}

\item{preds}{Character list or integer list. Names of columns or column indices of predictors. Default is to use the second and subsequent columns in \code{data}.}

\item{family}{Name of family for data error structure (see \code{?family}).}

\item{gamma}{Initial penalty to degrees of freedom to use (larger ==> smoother fits).}

\item{construct}{Logical. If \code{TRUE} then construct model by computing AICc for all univariate and bivariate models. Then add terms up to maximum set by \code{presPerTermInitial} and \code{initialTerms}.}

\item{select}{Logical. If \code{TRUE} then calculate AICc for all possible subsets of models and return the model with the lowest AICc of these. This step if performed \emph{after} model construction (if any).}

\item{presPerTermInitial}{Positive integer. Minimum number of presences needed per model term for a term to be included in the model construction stage. Used only if \code{construct} is \code{TRUE}.}

\item{presPerTermFinal}{Positive integer. Minimum number of presence sites per term in initial starting model; used only if \code{select} is \code{TRUE}.}

\item{initialTerms}{Positive integer. Maximum number of terms to be used in an initial model. Used only if \code{construct} is TRUE. The maximum that can be handled by \code{dredge()} is 31, so if this number is >31 and \code{select} is \code{TRUE} then it is forced to 31 with a warning. Note that the number of coefficients for factors is not calculated correctly, so if the predictors contain factors then this number might have to be reduced even more.}

\item{interaction}{Character or \code{NULL}. Type of interaction term to use (\code{te}, \code{ts}, \code{s}, etc.). See \code{?te} (for example) for help on any one of these. If \code{NULL} then interactions are not used.}

\item{w}{Either logical in which case TRUE causes the total weight of presences to equal the total weight of absences (if \code{family='binomial'}) OR a numeric list of weights, one per row in \code{data} OR the name of the column in \code{data} that contains site weights. The default is to assign a weight of 1 to each datum.}

\item{out}{Character vector. One or more values:
\itemize{
    \item    \code{'model'}: Model with the lowest AICc.
    \item    \code{'models'}: All models evaluated, sorted from lowest to highest AICc (lowest is best).
    \item    \code{'tuning'}: Data frame with tuning patrameters, one row per model, sorted by AICc.
}}

\item{verbose}{Logical. If TRUE then display intermediate results on the display device.}

\item{...}{Extra arguments (not used).}
}
\value{
If \code{out = 'model'} this function returns an object of class \code{gam}. If \code{out = 'tuning'} this function returns a data frame with tuning parameters and AICc for each model tried. If \code{out = c('model', 'tuning'} then it returns a list object with the \code{gam} object and the data frame.
}
\description{
This function constructs a GAM piece-by-piece by first calculating AICc for all models with univariate and bivariate (interaction) terms. It then creates a "full" model with the highest-ranked uni/bivariate terms then implements an all-subsets model selection routine.
}
\examples{

# The examples below show a very basic modeling workflow. They have been 
# designed to work fast, not produce accurate, defensible models.
set.seed(123)

### setup data

# environmental rasters
rastFile <- system.file('extdata/madEnv.tif', package='enmSdmX')
madEnv <- rast(rastFile)
madEnv <- madEnv / 100 # values were rounded to nearest 100th then * by 100

crs <- sf::st_crs(madEnv)

# lemur occurrence data
data(lemurs)
occs <- lemurs[lemurs$species == 'Eulemur fulvus', ]
occs <- sf::st_as_sf(occs, coords=c('longitude', 'latitude'), crs=crs)
occEnv <- extract(madEnv, occs, ID=FALSE)
occEnv <- occEnv[complete.cases(occEnv), ]
	
# create 10000 background sites (or as many as raster can support)
bgEnv <- terra::spatSample(madEnv, 20000)
bgEnv <- bgEnv[complete.cases(bgEnv), ]
bgEnv <- bgEnv[1:min(10000, nrow(bgEnv)), ]

# collate occurrences and background sites
presBg <- data.frame(
	presBg = c(
   rep(1, nrow(occEnv)),
   rep(0, nrow(bgEnv))
   )
)

env <- rbind(occEnv, bgEnv)
env <- cbind(presBg, env)

predictors <- c('bio1', 'bio12')

## MaxEnt
mx <- trainMaxEnt(
	data = env,
	resp = 'presBg',
	preds = predictors,
	regMult = 1, # too few values for reliable model, but fast
	verbose = TRUE
)

## generalized linear model (GLM)
# Normally, we'd center and standardize variables before modeling.
gl <- trainGlm(
	data = env,
	resp = 'presBg',
	preds = predictors,
	verbose = TRUE
)

## generalized additive model (GAM)
ga <- trainGam(
	data = env,
	resp = 'presBg',
	preds = predictors,
	verbose = TRUE
)

## natural splines
nat <- trainNs(
	data = env,
	resp = 'presBg',
	preds = predictors,
	verbose = TRUE
)

## boosted regression trees
envSub <- env[1:2000, ] # subsetting data to run faster
brt <- trainBrt(
	data = envSub,
	resp = 'presBg',
	preds = predictors,
	learningRate = 0.001, # too few values for reliable model(?)
	treeComplexity = 2, # too few values for reliable model, but fast
	minTrees = 1200, # minimum trees for reliable model(?), but fast
	maxTrees = 1200, # too small for reliable model(?), but fast
	tryBy = 'treeComplexity',
	anyway = TRUE, # return models that did not converge
	verbose = TRUE
)

## random forests
rf <- trainRf(
	data = env,
	resp = 'presBg',
	preds = predictors,
	verbose = TRUE
)

## make maps of models

mxMap <- predictEnmSdm(mx, madEnv)
glMap <- predictEnmSdm(gl, madEnv)
gaMap <- predictEnmSdm(ga, madEnv)
natMap <- predictEnmSdm(nat, madEnv)
brtMap <- predictEnmSdm(brt, madEnv)
rfMap <- predictEnmSdm(rf, madEnv)

maps <- c(
	mxMap,
	glMap,
	gaMap,
	natMap,
	brtMap,
	rfMap
)

names(maps) <- c('MaxEnt', 'GLM', 'GAM', 'Natural Splines', 'BRTs', 'RFs')
fun <- function() plot(occs[1], col='black', add=TRUE)
plot(maps, fun=fun)

## compare model responses to BIO12 (mean annual precipitation)

# make a data frame holding all other variables at mean across occurrences,
# varying only BIO12
occEnvMeans <- colMeans(occEnv, na.rm=TRUE)
occEnvMeans <- rbind(occEnvMeans)
occEnvMeans <- as.data.frame(occEnvMeans)
climFrame <- occEnvMeans[rep(1, 100), ]
rownames(climFrame) <- NULL

minBio12 <- min(env$bio12)
maxBio12 <- max(env$bio12)
climFrame$bio12 <- seq(minBio12, maxBio12, length.out=100)

predMx <- predictEnmSdm(mx, climFrame)
predGl <- predictEnmSdm(gl, climFrame)
predGa <- predictEnmSdm(ga, climFrame)
predNat <- predictEnmSdm(nat, climFrame)
predBrt <- predictEnmSdm(brt, climFrame)
predRf <- predictEnmSdm(rf, climFrame)


plot(climFrame$bio12, predMx,
xlab='BIO12', ylab='Prediction', type='l', ylim=c(0, 1))

lines(climFrame$bio12, predGl, lty='dotted', col='blue')
lines(climFrame$bio12, predGa, lty='dashed', col='green')
lines(climFrame$bio12, predNat, lty=4, col='purple')
lines(climFrame$bio12, predBrt, lty=5, col='orange')
lines(climFrame$bio12, predRf, lty=6, col='cyan')

legend(
   'topleft',
   inset = 0.01,
   legend = c(
	'MaxEnt',
	'GLM',
	'GAM',
	'NS',
	'BRT',
	'RF'
   ),
   lty = 1:6,
   col = c(
	'black',
	'blue',
	'green',
	'purple',
	'orange',
	'cyan'
   ),
   bg = 'white'
)


}
\seealso{
\code{\link[mgcv]{gam}}
}
